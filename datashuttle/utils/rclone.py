from __future__ import annotations

from typing import TYPE_CHECKING, Dict, List, Literal, Optional

if TYPE_CHECKING:
    from datashuttle.configs.config_class import Configs
    from datashuttle.utils.custom_types import TopLevelFolder, TransferErrors

import json
import os
import platform
import shlex
import subprocess
import tempfile
from subprocess import CompletedProcess

from datashuttle.configs import canonical_configs
from datashuttle.utils import utils


def call_rclone(command: str, pipe_std: bool = False) -> CompletedProcess:
    """Call rclone with the specified command.

    Parameters
    ----------
    command
        Rclone command to be run

    pipe_std
        if True, do not output anything to stdout.

    Returns
    -------
    subprocess.CompletedProcess with `stdout` and `stderr` attributes.

    """
    command = "rclone " + command
    if pipe_std:
        output = subprocess.run(
            command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True
        )
    else:
        output = subprocess.run(command, shell=True)

    if output.returncode != 0:
        prompt_rclone_download_if_does_not_exist()

    return output


def call_rclone_through_script(command: str) -> CompletedProcess:
    """Call rclone through a script.

    This is to avoid limits on command-line calls (in particular on Windows).
    Used for transfers due to generation of large call strings.

    Parameters
    ----------
    command
        Full command to run with RClone.

    Returns
    -------
    subprocess.CompletedProcess with `stdout` and `stderr` attributes.

    """
    system = platform.system()

    command = "rclone " + command

    if system == "Windows":
        suffix = ".bat"
    else:
        suffix = ".sh"
        command = "#!/bin/bash\n" + command

    with tempfile.NamedTemporaryFile(
        mode="w", suffix=suffix, delete=False
    ) as tmp_script:
        tmp_script.write(command)
        tmp_script_path = tmp_script.name

    try:
        if system != "Windows":
            os.chmod(tmp_script_path, 0o700)

        output = subprocess.run(
            [tmp_script_path],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            shell=False,
        )

        if output.returncode != 0:
            prompt_rclone_download_if_does_not_exist()

    finally:
        os.remove(tmp_script_path)

    return output


def call_rclone_with_popen(command: str) -> subprocess.Popen:
    """Call rclone using `subprocess.Popen` for control over process termination.

    It is not possible to kill a process while running it using `subprocess.run`.
    Killing a process might be required when running rclone setup in a thread worker
    to allow the user to cancel the setup process. In such a case, cancelling the
    thread worker alone will not kill the rclone process, so we need to kill the
    process explicitly.
    """
    command = "rclone " + command
    process = subprocess.Popen(
        shlex.split(command), stdout=subprocess.PIPE, stderr=subprocess.PIPE
    )
    return process


def await_call_rclone_with_popen_raise_on_fail(
    process: subprocess.Popen, log: bool = True
):
    """Await rclone the subprocess.Popen call.

    Calling `process.communicate()` waits for the process to complete and returns
    the stdout and stderr.
    """
    stdout, stderr = process.communicate()

    if process.returncode != 0:
        utils.log_and_raise_error(stderr.decode("utf-8"), ConnectionError)

    if log:
        log_rclone_config_output()


# -----------------------------------------------------------------------------
# Setup
# -----------------------------------------------------------------------------


def setup_rclone_config_for_local_filesystem(
    rclone_config_name: str,
    log: bool = True,
) -> None:
    """Set the RClone remote config for local filesystem.

    RClone sets remote targets in a config file that are
    used at transfer. For local filesystem, this is essentially
    a placeholder and that is not linked to a particular filepath.
    It just tells rclone to use the local filesystem - then we
    supply the filepath at transfer time.

    For local filesystem, this is just a placeholder and
    the config contains no further information.

    For SSH, this contains information for
    connecting to central with SSH.

    Parameters
    ----------
    rclone_config_name
        canonical config name, generated by
        datashuttle.cfg.get_rclone_config_name()

    log
        whether to log, if True logger must already be initialised.

    """
    call_rclone(f"config create {rclone_config_name} local", pipe_std=True)

    if log:
        log_rclone_config_output()


def setup_rclone_config_for_ssh(
    cfg: Configs,
    rclone_config_name: str,
    private_key_str: str,
    log: bool = True,
) -> None:
    """Set the RClone remote config for ssh.

    RClone sets remote targets in a config file that are
    used at transfer. For SSH, this must contain the central path,
    username and ssh key. The relative path is supplied at transfer time.

    Parameters
    ----------
    cfg
        datashuttle configs UserDict.

    rclone_config_name
        canonical config name, generated by
        datashuttle.cfg.get_rclone_config_name()

    private_key_str
        PEM encoded ssh private key to pass to RClone.

    log
        whether to log, if True logger must already be initialised.

    """
    key_escaped = private_key_str.replace("\n", "\\n")

    command = (
        f"config create "
        f"{rclone_config_name} "
        f"sftp "
        f"host {cfg['central_host_id']} "
        f"user {cfg['central_host_username']} "
        f"port {canonical_configs.get_default_ssh_port()} "
        f'-- key_pem "{key_escaped}"'
    )

    call_rclone(command, pipe_std=True)

    if log:
        log_rclone_config_output()


def setup_rclone_config_for_gdrive(
    cfg: Configs,
    rclone_config_name: str,
    gdrive_client_secret: str | None,
    config_token: Optional[str] = None,
) -> subprocess.Popen:
    """Set up rclone config for connections to Google Drive.

    This function uses `call_rclone_with_popen` instead of `call_rclone`. This
    is done to have more control over the setup process in case the user wishes to
    cancel the setup. Since the rclone setup for google drive uses a local web server
    for authentication to google drive, the running process must be killed before the
    setup can be started again.

    Parameters
    ----------
    cfg
       datashuttle configs UserDict. This must contain the `gdrive_root_folder_id`
       and optionally a `gdrive_client_id` which also mandates for the presence
       of a Google Drive client secret.

    rclone_config_name
         Canonical config name, generated by
         datashuttle.cfg.get_rclone_config_name()

    gdrive_client_secret
        Google Drive client secret, mandatory when using a Google Drive client.

    config_token : a token to setup rclone config without opening a browser,
        needed if the user's machine doesn't have access to a browser.

    """
    client_id_key_value = (
        f"client_id {cfg['gdrive_client_id']} "
        if cfg["gdrive_client_id"]
        else " "
    )
    client_secret_key_value = (
        f"client_secret {gdrive_client_secret} "
        if gdrive_client_secret
        else ""
    )

    extra_args = (
        f"config_is_local=false config_token={config_token}"
        if config_token
        else ""
    )

    process = call_rclone_with_popen(
        f"config create "
        f"{rclone_config_name} "
        f"drive "
        f"{client_id_key_value}"
        f"{client_secret_key_value}"
        f"scope drive "
        f"root_folder_id {cfg['gdrive_root_folder_id']} "
        f"{extra_args}"
    )

    return process


def setup_rclone_config_for_aws(
    cfg: Configs,
    rclone_config_name: str,
    aws_secret_access_key: str,
    log: bool = True,
):
    """Set up rclone config for connections to AWS S3 buckets.

    Parameters
    ----------
    cfg
       datashuttle configs UserDict.
       Must contain the `aws_access_key_id` and `aws_region`.

    rclone_config_name
        Canonical RClone config name, generated by
        datashuttle.cfg.get_rclone_config_name()

    aws_secret_access_key
        The aws secret access key provided by the user.

    log
        Whether to log, if True logger must already be initialised.

    """
    aws_region = cfg["aws_region"]

    # Rclone mandates location_constraint be set as the aws regions for
    # all regions except us-east-1
    location_constraint_key_value = (
        ""
        if aws_region == "us-east-1"
        else f" location_constraint {aws_region}"
    )

    output = call_rclone(
        "config create "
        f"{rclone_config_name} "
        "s3 provider AWS "
        f"access_key_id {cfg['aws_access_key_id']} "
        f"secret_access_key {aws_secret_access_key} "
        f"region {aws_region}"
        f"{location_constraint_key_value}",
        pipe_std=True,
    )

    if output.returncode != 0:
        utils.log_and_raise_error(
            output.stderr.decode("utf-8"), ConnectionError
        )

    if log:
        log_rclone_config_output()


def check_successful_connection_and_raise_error_on_fail(cfg: Configs) -> None:
    """Check for a successful connection by creating a file on the remote.

    If the command fails, it raises a ConnectionError. The created file is
    deleted thereafter.
    """
    filename = f"{utils.get_random_string()}_temp.txt"

    if cfg["central_path"] is None:
        assert cfg["connection_method"] == "gdrive", (
            "`central_path` may only be `None` for `gdrive`"
        )
        tempfile_path = filename
    else:
        tempfile_path = (cfg["central_path"] / filename).as_posix()

    output = call_rclone(
        f"touch {cfg.get_rclone_config_name()}:{tempfile_path}", pipe_std=True
    )
    if output.returncode != 0:
        utils.log_and_raise_error(
            output.stderr.decode("utf-8"), ConnectionError
        )

    output = call_rclone(
        f"delete {cfg.get_rclone_config_name()}:{tempfile_path}", pipe_std=True
    )
    if output.returncode != 0:
        utils.log_and_raise_error(
            output.stderr.decode("utf-8"), ConnectionError
        )


def log_rclone_config_output() -> None:
    """Log the output from creating Rclone config."""
    output = call_rclone("config file", pipe_std=True)
    utils.log(
        f"Successfully created rclone config. {output.stdout.decode('utf-8')}"
    )


def prompt_rclone_download_if_does_not_exist() -> None:
    """Check that rclone is installed."""
    if not check_rclone_with_default_call():
        newline = "" if "PYTEST_CURRENT_TEST" in os.environ else "\n"

        utils.log_and_raise_error(
            f"RClone installation not found. Install by entering "
            f"the following into your terminal:{newline}"
            f"  conda install -c conda-forge rclone",
            RuntimeError,
        )


def check_rclone_with_default_call() -> bool:
    """Return a bool indicating whether rclone is installed.

    Must not use `call_rclone` or leads to recursion.
    """
    try:
        output = subprocess.run(
            "rclone -h",
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            shell=True,
        )
    except FileNotFoundError:
        return False
    return True if output.returncode == 0 else False


# -----------------------------------------------------------------------------
# Transfer
# -----------------------------------------------------------------------------


def transfer_data(
    cfg: Configs,
    upload_or_download: Literal["upload", "download"],
    top_level_folder: TopLevelFolder,
    include_list: List[str],
    rclone_options: Dict,
) -> subprocess.CompletedProcess:
    """Transfer data by making a call to Rclone.

    Parameters
    ----------
    cfg
        datashuttle configs

    upload_or_download
        If "upload", transfer from `local_path` to `central_path`.
        "download" proceeds in the opposite direction.

    top_level_folder
        The top-level-folder to transfer files within.

    include_list
        A list of filepaths to include in the transfer

    rclone_options
        A list of options to pass to Rclone's copy function.
        see `cfg.make_rclone_transfer_options()`.

    Returns
    -------
    subprocess.CompletedProcess with `stdout` and `stderr` attributes.

    """
    assert upload_or_download in [
        "upload",
        "download",
    ], "must be 'upload' or 'download'"

    local_filepath = cfg.get_base_folder("local", top_level_folder).as_posix()

    central_filepath = cfg.get_base_folder(
        "central", top_level_folder
    ).as_posix()

    extra_arguments = handle_rclone_arguments(rclone_options, include_list)

    if upload_or_download == "upload":
        output = call_rclone_through_script(
            f"{rclone_args('copy')} "
            f'"{local_filepath}" "{cfg.get_rclone_config_name()}:'
            f'{central_filepath}" {extra_arguments} --use-json-log',
        )

    elif upload_or_download == "download":
        output = call_rclone_through_script(
            f"{rclone_args('copy')} "
            f'"{cfg.get_rclone_config_name()}:'
            f'{central_filepath}" "{local_filepath}" {extra_arguments} --use-json-log',
        )

    return output


def log_stdout_stderr_python_api(stdout: str, stderr: str) -> None:
    """Log `stdout` and `stderr`."""
    message = (
        f"\n\n**************  STDOUT  **************\n"
        f"{stdout}"
        f"\n\n**************  STDERR  **************\n"
        f"{stderr}"
    )

    utils.log_and_message(message)


def log_rclone_copy_errors_api(errors):
    """Log the `errors` dictionary.

    The `errors` dictionary contains all pertinent information on
    issues that occurred when running `rclone copy`. Note this logs
    for the API, the TUI display is handled separately.

    Note this function is very similar
    to `handle_transfer_and_update_ui_when_complete`
    but kept separate for flexibility.
    """
    message = ""

    if errors["nothing_was_transferred_rawdata"] is True:
        message += "\n\nNote! Nothing was transferred from rawdata!\n"

    if errors["nothing_was_transferred_derivatives"] is True:
        message += "\n\nNote! Nothing was transferred from derivatives!\n"

    if any(errors["messages"]):
        if any(errors["file_names"]):
            message += (
                "\n\nErrors were detected! In files:"
                "\n-------------------------------\n"
            )
            message += "\n".join(errors["file_names"])
        else:
            message += "\n\n[red]Errors detected![/red]"
        message += "\n\nThe error messages are:\n-----------------------\n"
        message += "\n".join(errors["messages"])
        message += "\n"

    if message == "":
        message = "No errors detected"

    utils.log_and_message(message, use_rich=True)


def parse_rclone_copy_output(top_level_folder, output):
    """Format the `rclone copy` output ready for logging.

    Reformat and combine the string streams and `errors`
    dictionary from stdout and stderr output of `rclone copy`.
    see `reformat_rclone_copy_output() for details.
    """
    stdout, out_errors = reformat_rclone_copy_output(
        output.stdout, top_level_folder=top_level_folder
    )

    stderr, err_errors = reformat_rclone_copy_output(
        output.stderr, top_level_folder=top_level_folder
    )

    # Combine the two `errors` output
    all_errors = {
        "file_names": out_errors["file_names"] + err_errors["file_names"],
        "messages": out_errors["messages"] + err_errors["messages"],
        "nothing_was_transferred_rawdata": err_errors[
            "nothing_was_transferred_rawdata"
        ],
        "nothing_was_transferred_derivatives": err_errors[
            "nothing_was_transferred_derivatives"
        ],
    }

    all_errors["file_names"] = list(set(all_errors["file_names"]))

    return stdout, stderr, all_errors


def get_empty_errors_dict() -> TransferErrors:
    """Return the `errors` dictionary with default values.

    The `errors` dictionary holds information
    about errors which occurred during `rclone copy` transfer.
    The dict entries are:

    file_names
        A list of file names associated with errors.

    messages
        A list of messages associated with errors. For each file name,
        there will be an associated message, but it is also possible to
        have messages that are not associated with any file name.

    nothing_was_transferred_rawdata
        A flag that can take the value `None`, `True` or `False`.
        If `None`, this top-level folder was not attempted to be transferred.
        If `True`, it was attempted and nothing was transferred. If `False`,
        it was attempted and something was transferred.

    nothing_was_transferred_derivatives
        See `nothing_was_transferred_rawdata`, this is the equivalent for
        the derivatives' folder.

    The rawdata and derivatives flags must be split as some functions
    transfer a single, or both, top level folders in one command.
    """
    return {
        "file_names": [],
        "messages": [],
        "nothing_was_transferred_rawdata": None,
        "nothing_was_transferred_derivatives": None,
    }


def reformat_rclone_copy_output(
    stream: bytes,
    top_level_folder: TopLevelFolder | None = None,
) -> tuple[str, TransferErrors]:
    """Parse the output of `rclone copy` for convenient error checking.

    Rclone's `copy` command (called with `--use-json-log`) outputs a lot of
    information related to the transfer. We dump this in text form to a log
    file. However, we also want to grab any key events (errors, or complete
    lack of transferred files) so these can be displayed separately.

    This function iterates through all lines in the `rclone copy` output.
    This output is typically a mix of string format and json format.
    If the line is json-encoded, then we extract important information
    and format it to string, and re-insert it into the output.

    In this way, we have a string-format output ready to be
    dumped to the logs, as well as an `errors` dictionary containing
    details on all key information.

    Returns
    -------
    format_stream
        The input stream, converted to string and with all
        json-formatted lines reformatted as string. This is ready
        to be dumped to a log file.

    errors
        A dictionary (`TransferErrors`) containing key information
        about issues in the transfer.

    """
    split_stream = stream.decode("utf-8").split("\n")

    errors = get_empty_errors_dict()

    for idx, line in enumerate(split_stream):
        try:
            line_json = json.loads(line)
        except json.JSONDecodeError:
            continue

        if line_json["level"] in ["error", "critical"]:
            if "object" in line_json:
                full_filepath = f"{top_level_folder}/{line_json['object']}"
                errors["file_names"].append(full_filepath)
                errors["messages"].append(
                    f"The file {full_filepath} failed to transfer. Reason: {line_json['msg']}"
                )
            else:
                errors["messages"].append(f"ERROR : {line_json['msg']}")

        elif "stats" in line_json and "totalTransfers" in line_json["stats"]:
            if line_json["stats"]["totalTransfers"] == 0:
                errors[f"nothing_was_transferred_{top_level_folder}"] = True  # type:ignore
            else:
                errors[f"nothing_was_transferred_{top_level_folder}"] = False  # type:ignore

        split_stream[idx] = (
            f"{line_json['time'][:19]} {line_json['level'].upper()} : {line_json['msg']}"
        )

    format_stream = "\n".join(split_stream)

    return format_stream, errors


def get_local_and_central_file_differences(
    cfg: Configs,
    top_level_folders_to_check: List[TopLevelFolder],
) -> Dict:
    """Format a structure of all changes between local and central.

    Rclone output comes as a list of files, separated by newlines,
    with symbols indicating whether the file paths are same across
    local and central, different, or found in local / central only.

    Convert the output of Rclone's check (with `--combine`) flag
    to a dictionary separating each case.

    Parameters
    ----------
    cfg
        datashuttle configs UserDict.

    top_level_folders_to_check
        List of top-level folders to check.

    Returns
    -------
    parsed_output
        A dictionary where the keys are the cases (e.g. "same" across
        local and central) and the values are lists of paths that
        fall into these cases. Note the paths are relative to the "rawdata"
        folder.

    """
    convert_symbols = {
        "=": "same",
        "*": "different",
        "+": "local_only",
        "-": "central_only",
        "!": "error",
    }

    parsed_output: Dict[str, List]
    parsed_output = {val: [] for val in convert_symbols.values()}

    for top_level_folder in top_level_folders_to_check:
        rclone_output = perform_rclone_check(cfg, top_level_folder)  # type: ignore
        split_rclone_output = rclone_output.split("\n")

        for result in split_rclone_output:
            if result == "":
                continue

            symbol = result[0]

            assert_rclone_check_output_is_as_expected(
                result, symbol, convert_symbols
            )

            key = convert_symbols[symbol]
            parsed_output[key].append(result[2:])

    return parsed_output


def assert_rclone_check_output_is_as_expected(result, symbol, convert_symbols):
    """Ensure the output of Rclone check is as expected.

    Currently, the "error" case is untested and a test case is required.
    Once the test case is obtained this should most likely be moved to tests.
    """
    assert result[1] == " ", (
        "`rclone check` output does not contain a "
        "space as the second character`."
    )
    assert symbol in convert_symbols.keys(), "rclone check symbol is unknown."
    assert symbol != "!", (
        "Could not complete rlcone check. "
        "This is unexpected. Please contact datashuttle "
        "at our GitHub page."
    )


def perform_rclone_check(
    cfg: Configs, top_level_folder: TopLevelFolder
) -> str:
    r"""Run RClone check to find differences in files between local and central.

    Use Rclone's `check` command to build a list of files that
    are the same ("="), different ("*"), found in local only ("+")
    or central only ("-"). The output is formatted as "\<symbol> \<path>\n".
    """
    local_filepath = cfg.get_base_folder(
        "local", top_level_folder
    ).parent.as_posix()
    central_filepath = cfg.get_base_folder(
        "central", top_level_folder
    ).parent.as_posix()

    output = call_rclone(
        f"{rclone_args('check')} "
        f'"{local_filepath}" '
        f'"{cfg.get_rclone_config_name()}:{central_filepath}"'
        f" --combined -",
        pipe_std=True,
    )

    return output.stdout.decode("utf-8")


def handle_rclone_arguments(
    rclone_options: Dict, include_list: List[str]
) -> str:
    """Construct the extra arguments to pass to RClone.

    Parameters
    ----------
    rclone_options
        A list of option keywords to be passed to

    include_list
        The (already formatted) list of filepaths for the
        rclone `--include` option.

    Returns
    -------
    A full list of arguments to pass to rclone.

    """
    extra_arguments_list = []

    extra_arguments_list += ["-" + rclone_options["transfer_verbosity"]]

    overwrite = rclone_options["overwrite_existing_files"]

    if overwrite == "never":
        extra_arguments_list += [rclone_args("never_overwrite")]

    elif overwrite == "always":
        pass

    elif overwrite == "if_source_newer":
        extra_arguments_list += [rclone_args("if_source_newer_overwrite")]

    if rclone_options["show_transfer_progress"]:
        extra_arguments_list += [rclone_args("progress")]

    if rclone_options["dry_run"]:
        extra_arguments_list += [rclone_args("dry_run")]

    extra_arguments_list += include_list

    extra_arguments = " ".join(extra_arguments_list)

    return extra_arguments


def rclone_args(name: str) -> str:
    """Return list of Rclone commands."""
    valid_names = [
        "dry_run",
        "copy",
        "never_overwrite",
        "if_source_newer_overwrite",
        "progress",
        "check",
    ]
    assert name in valid_names, f"`name` must be in: {valid_names}"

    if name == "dry_run":
        arg = "--dry-run"

    if name == "copy":
        arg = "copy"

    if name == "never_overwrite":
        arg = "--ignore-existing"

    if name == "if_source_newer_overwrite":
        arg = "--update"

    if name == "progress":
        arg = "--progress"

    if name == "check":
        arg = "check"

    return arg
